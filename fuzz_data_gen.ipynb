{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_est(rets):\n",
    "    num_succ = len(rets)\n",
    "    sum_succ=0;sum_fails=0;sum_feats=0; total_wait = 0; max_succ=-1; max_fails=-1;p_all_fail = 1; markov_bound = 20; geom_all_fail=1; p_succ_sum=0; geom_bound=2;p_min=2\n",
    "    max_smoothing=0.99\n",
    "    for key,value in rets.items():\n",
    "        trials_succ = value['trials']\n",
    "        if max_succ == 0:  \n",
    "            max_succ = trials_succ\n",
    "        else:\n",
    "            max_succ = max(max_smoothing * max_succ, trials_succ)  # exponential decay\n",
    "        sum_succ += trials_succ\n",
    "        sum_fails += sum(value['fails']) # sum cur fails\n",
    "        max_fails = max(sum_fails,max_fails) # max of fails\n",
    "        total_wait += trials_succ+sum_fails # overall since begining\n",
    "        sum_feats += value['features'] # overall\n",
    "    \n",
    "    est_max = max_succ*num_succ # estimate looks at worst case success of a seed, multiply it by the number of seeds generated OR just successful seeds?? e\n",
    "    est_avgseed = num_succ and total_wait/num_succ or 0 # sum all fails+succ trial and divide by num successes\n",
    "    est_avgfeat = sum_feats and total_wait/sum_feats or 0\n",
    "    est_markov = est_avgseed*markov_bound\n",
    "    alpha = 1; beta = 1\n",
    "    for key,value in rets.items():\n",
    "        trials_succ = value['trials']\n",
    "        p_this_succ = (1+alpha)/((trials_succ-1)+alpha+beta) # uninformative prior, bayesian smoothign for prob estimate\n",
    "        p_this_fail = 1-p_this_succ # fail rate\n",
    "        p_succ_sum += p_this_succ\n",
    "        p_min = min(p_min,p_this_succ)\n",
    "        p_all_fail = p_all_fail*p_this_fail # all fail chance\n",
    "        geom_all_fail = geom_all_fail*(p_this_fail**geom_bound) # (1-p)^(5E(t)) , prob that all require more than 5 times expected val\n",
    "        alpha+=1\n",
    "        # beta+=sum(value['fails'])\n",
    "        beta += (trials_succ-1)\n",
    "    \n",
    "    # p_geom_ident = num_succ/sum_succ # 1/bar(X)\n",
    "    p_geom_ident = num_succ/total_wait # succ/total_time\n",
    "    # geom_bound *= sum_succ/num_succ # bound = 20*E(X)\n",
    "    geom_bound *= max_succ # bound = 5*Max trials for succ\n",
    "    p_geom_ident = (1-p_geom_ident)**geom_bound # bound by 5* expected value of finding a seed?, (1-p)^bound, P(more than bound)\n",
    "    p_geom_ident = 1-p_geom_ident # P(less than bound) = 1-P(more than bound)\n",
    "    # p_atl = 1-(p_all_fail) # at least one succ\n",
    "    p_atl = 1-((1-p_min)**num_succ) # use worst seed in at least one success?\n",
    "    est_atl = num_succ/p_atl\n",
    "    p_geom_nonident = 1-geom_all_fail # at least 1 require less than max time\n",
    "    est_geom_nonident = p_geom_nonident and (num_succ*geom_bound)/p_geom_nonident or 0 # the time required for at least 1 seed to get succ in less than expected number of trials, can add a multiplier too\n",
    "    est_geom_ident = p_geom_ident and (geom_bound)/p_geom_ident or 0\n",
    "    # p_succ_cum = p_succ_cum/num_succ # each seed can be picked with equal prob, this is including overlaps, reduce later\n",
    "    return est_max,est_avgseed,est_avgfeat,est_atl,est_geom_nonident,est_markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    all_ret = {}\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        line2 = lines[i+1].strip()\n",
    "        point, rest = line.split(\", \", 1)  # Split only on the first \", \"\n",
    "        point = int(point)\n",
    "        trials = int(rest)\n",
    "        part2 = line2.split(\", \",1)\n",
    "        if len(part2)>1:\n",
    "            fails = [int(x) for x in part2[1].split(\",\") if x.strip()]\n",
    "        else:\n",
    "            fails=[0]\n",
    "        all_ret[int(i/8)] = {\n",
    "            'point': point,\n",
    "            'trials': trials,\n",
    "            'fails': fails,\n",
    "            'features': int(lines[i + 2].strip().split(\", \")[1]),\n",
    "            'llaplace': int(lines[i + 3].strip().split(\", \")[1]),\n",
    "            'lgt': int(lines[i + 4].strip().split(\", \")[1]),\n",
    "            'maxfork': int(lines[i + 5].strip().split(\", \")[1]),\n",
    "            'avgfork': int(lines[i + 6].strip().split(\", \")[1]),\n",
    "            'rate': int(lines[i + 7].strip().split(\", \")[1])\n",
    "        }\n",
    "        i += 8\n",
    "    return all_ret\n",
    "\n",
    "def generate_csv(file_name):\n",
    "    file_path = f'data/{file_name}.txt'\n",
    "    all_ret = parse_file(file_path)\n",
    "    trials_to_succ = 0;inputs = [];overall_trials = 0;overall_features = 0;all_ret_so_far={}\n",
    "    # history_range = range(20,161,20) ## look at past discoveries?\n",
    "    # history_range = [] ## look at past discoveries?\n",
    "\n",
    "    for i in range(len(all_ret)):\n",
    "        succ_trials = all_ret[i]['trials'] # in OG run what is the number trials it took from all seeds which are being reset between every 2 discoveries, same as point[i]-point[i-1]\n",
    "        fails = sum(all_ret[i]['fails']) # fails vect\n",
    "        trials_to_succ = 0\n",
    "        trials_to_succ = fails+succ_trials # sum both gives total btw 2 disc\n",
    "        features = all_ret[i]['features']\n",
    "        overall_trials = overall_trials+trials_to_succ\n",
    "        overall_features = overall_trials+features\n",
    "        rate = all_ret[i]['rate']\n",
    "        all_ret_so_far[i] = all_ret[i]\n",
    "        estimates=[]\n",
    "        if(i!=0):\n",
    "            maxfork = all_ret[i-1]['maxfork']\n",
    "            avgfork = all_ret[i-1]['avgfork']\n",
    "            # for h in history_range: ## when im at point i=10, need to use values 7,8,9 if h=3, when at i=1, need to use values 0 for h=1, and none from h=2\n",
    "            #     if i < h: # 1<2\n",
    "            #         ests = [0,0,0,0,0,0]\n",
    "            #     else:\n",
    "            #         ## h=2, i=10 : all_ret[(i-h:(i-1)] [8,9], h=1, i=1 : all_ret[0:i-1]\n",
    "            #         hist_ret = {k: all_ret[k] for k in range(i-h, i) if k in all_ret}\n",
    "            #         ests = calc_est(hist_ret)\n",
    "            #     ests = [round(est) for est in ests]\n",
    "            #     estimates.extend(ests)\n",
    "            ests = calc_est(all_ret_so_far)\n",
    "            ests = [round(est) for est in ests]\n",
    "            estimates.extend(ests)\n",
    "        else:\n",
    "            maxfork = 0\n",
    "            avgfork = 0\n",
    "            estimates = [0,0,0,0,0,0]\n",
    "\n",
    "        ######### Shift the fork max/avg values down by one because we fork after finding the seed in GB############\n",
    "        # seed_limit = 1; fork_limit = 10; # _ ---> doing this\n",
    "        est_ll = all_ret[i]['llaplace']\n",
    "        est_lgt = all_ret[i]['lgt']\n",
    "        defaults = [features,overall_trials,overall_features,succ_trials,trials_to_succ,maxfork,avgfork,rate,est_ll,est_lgt]\n",
    "        inputs.append([i] + defaults + estimates) # appending the estimate for point i made from i-1 and before, comparing against trials at point i, and \n",
    "        \n",
    "    headers = [\"Index\",\"Features\",\"OverallTrials\",\"OverallFeatures\",\"SuccTrials\",\"TrialsToDisc\",\"MaxFork\",\"AvgFork\", \"Rate\", \"LLaplace\",\"LGT\"]\n",
    "    # for h in history_range:\n",
    "        # headers.extend([f\"MaxTrials_{h}\",f\"AvPath_{h}\",f\"AvFeat_{h}\",f\"ATL_{h}\",f\"Extr_{h}\",f\"Markov_{h}\"])\n",
    "    headers.extend([f\"MaxTrials_all\",f\"AvPath_all\",f\"AvFeat_all\",f\"ATL_all\",f\"Extr_all\",f\"Markov_all\"])\n",
    "    with open(f\"./data/csv/{file_name}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(headers)\n",
    "            writer.writerows(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uests(true_col, est_col):\n",
    "    true_col = pd.Series(true_col)\n",
    "    est_col = pd.Series(est_col)\n",
    "    underestimates = (true_col>est_col)  # Boolean mask for underestimations\n",
    "    cnt_uest = ((np.nansum(underestimates.astype(int))) / len(underestimates)) * 100\n",
    "    diff = true_col - est_col  # Raw difference\n",
    "    diff = np.where(np.isfinite(diff), diff, 0)\n",
    "    if diff[underestimates].size > 0:\n",
    "        max_uest = diff[underestimates].max()\n",
    "    else:\n",
    "        max_uest = 1\n",
    "    rel_diff = (diff / true_col) * 100  # Percentage error\n",
    "    if rel_diff[underestimates].size > 0:\n",
    "        rel = rel_diff[underestimates].mean()\n",
    "    else:\n",
    "        rel = 0\n",
    "    non_zero_diff = diff[underestimates][diff[underestimates] != 0]\n",
    "    if len(non_zero_diff) > 0:\n",
    "        min_uest = non_zero_diff.min()\n",
    "    else:\n",
    "        min_uest = 1\n",
    "\n",
    "    return cnt_uest,max_uest,min_uest,rel\n",
    "\n",
    "def get_oests(true_col, est_col):\n",
    "    true_col = pd.Series(true_col)\n",
    "    est_col = pd.Series(est_col)\n",
    "    overestimates = ((true_col<est_col) & (true_col != 0))\n",
    "    diff = est_col-true_col\n",
    "    rel_diff = (diff / true_col) * 100 \n",
    "    # print(\"Diff:\",diff,\"True:\",true_col,\"rel diff:\",rel_diff)\n",
    "    if diff[overestimates].size > 0:\n",
    "        max_oest = diff[overestimates].max()\n",
    "    else:\n",
    "        max_oest = 1\n",
    "    severe = diff>4000 # worse than 4000 s of overprediction?\n",
    "    if diff[severe].size > 0:\n",
    "        severe_overestimation = diff[severe].mean()\n",
    "    else:\n",
    "        severe_overestimation = 1\n",
    "\n",
    "    return max_oest,severe_overestimation,rel_diff[overestimates].mean()\n",
    "\n",
    "# Concordance correlation coefficient\n",
    "def get_ccc(true_col, est_col):\n",
    "    true_col = pd.Series(true_col)\n",
    "    est_col = pd.Series(est_col)\n",
    "    data = pd.concat([true_col, est_col], axis=1)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    true_col = data.iloc[:, 0]\n",
    "    est_col = data.iloc[:, 1]\n",
    "    if len(true_col) == 0:\n",
    "        return np.nan\n",
    "    mean_true = true_col.mean()\n",
    "    mean_est = est_col.mean()\n",
    "    var_true = true_col.var()\n",
    "    var_est = est_col.var()\n",
    "    std_true = np.sqrt(var_true)\n",
    "    std_est = np.sqrt(var_est)\n",
    "    correlation = true_col.corr(est_col)\n",
    "    ccc = (2 * correlation * std_true * std_est) / (\n",
    "        var_true + var_est + (mean_true - mean_est) ** 2\n",
    "    )\n",
    "    return ccc\n",
    "\n",
    "def get_smape(y_true, y_pred, under_weight=2, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Compute Symmetric Mean Absolute Percentage Error (SMAPE).\n",
    "    Parameters:\n",
    "    - y_true: array-like of true values\n",
    "    - y_pred: array-like of predicted values\n",
    "    - epsilon: small value to avoid division by zero\n",
    "    Returns:\n",
    "    - smape_value: float, SMAPE in percentage (0 to 200%)\n",
    "    \"\"\"\n",
    "    y_true = pd.Series(y_true)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "    data = pd.concat([y_true, y_pred], axis=1)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y_true = data.iloc[:, 0]\n",
    "    y_pred = data.iloc[:, 1]\n",
    "    if len(y_true) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    denominator = np.where(denominator == 0, epsilon, denominator)\n",
    "    errors = y_pred - y_true\n",
    "    weights = np.where(errors < 0, under_weight, 1.0)\n",
    "    smape_values = weights*np.abs(errors) / denominator\n",
    "    return 100 * np.mean(smape_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col(method, n, estimates):\n",
    "        if method == 'ATL':\n",
    "            return estimates.filter(regex=f'ATL_{n}$').values.flatten()\n",
    "        elif method == 'AvPath':\n",
    "            return estimates.filter(regex=f'AvPath_{n}$').values.flatten()\n",
    "        elif method == 'AvFeat':\n",
    "            return estimates.filter(regex=f'AvFeat_{n}$').values.flatten()\n",
    "        elif method == 'MaxTrials':\n",
    "            return estimates.filter(regex=f'MaxTrials_{n}$').values.flatten()\n",
    "        elif method == 'Markov':\n",
    "            return estimates.filter(regex=f'Markov_{n}$').values.flatten()\n",
    "        elif method == 'Extr':\n",
    "            return estimates.filter(regex=f'Extr_{n}$').values.flatten()\n",
    "        elif method == 'LLaplace':\n",
    "            return estimates.filter(regex=f'LLaplace$').values.flatten()\n",
    "        elif method == 'LGT':\n",
    "            return estimates.filter(regex=f'LGT$').values.flatten()    \n",
    "        elif method == 'Rate':\n",
    "            return estimates.filter(regex=f'Rate$').values.flatten()\n",
    "        \n",
    "def plot_stats(file_name, plot_type):\n",
    "    df = pd.read_csv(f'./data/csv/{file_name}.csv')\n",
    "    columns = df.columns.tolist()\n",
    "    orig_values = list(df['TrialsToDisc'])\n",
    "    max_fork_values = list(df['MaxFork'])\n",
    "    avg_fork_values = list(df['AvgFork'])\n",
    "    estimates = df[columns[8:]] ## dont hardcode\n",
    "    # remove = [\"ExWait\"]\n",
    "    # pattern = '|'.join(remove)\n",
    "    # cols_remove = estimates.filter(regex=pattern).columns\n",
    "    # estimates = estimates.drop(columns=cols_remove)\n",
    "    cols_dict = {\n",
    "        'LLaplace': get_col('LLaplace', 0,estimates),\n",
    "        'LGT': get_col('LGT', 0,estimates),\n",
    "        'Rate': get_col('Rate',0,estimates),\n",
    "    }\n",
    "    rate = np.array(cols_dict['Rate'], dtype=object)\n",
    "    rate = pd.to_numeric(rate, errors='coerce')\n",
    "    rate = np.nan_to_num(rate, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "    \n",
    "    if plot_type == \"errors\":\n",
    "        #### Risk averse Errors plots ########\n",
    "        # single metric #\n",
    "        smape_dict = {}\n",
    "        for col in estimates.columns:\n",
    "            if col!= 'Rate' and col!=\"\":\n",
    "                # ccc = get_ccc(max_fork_values/rate,estimates[col]/rate)\n",
    "                smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
    "                smape_dict[col] = smape\n",
    "                # print(col,ccc)\n",
    "        # fig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(16, 16))\n",
    "        # vals = list(cnt_uest_dict.values())\n",
    "        # ax1.bar(cnt_uest_dict.keys(),vals)\n",
    "        # ax1.set_title('Uest Counts', fontsize=16)\n",
    "        # ax1.set_xlabel('Estimate', fontsize=16)\n",
    "        # ax1.set_ylabel('Counts %', fontsize=16)\n",
    "        # ax1.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        \n",
    "        # Uest #\n",
    "        cnt_uest_dict = {}\n",
    "        max_dict = {}\n",
    "        min_dict = {}\n",
    "        rel_uest_avg_dict = {}\n",
    "        for col in estimates.columns:\n",
    "            if col!= 'Rate' and col!=\"\":\n",
    "                cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
    "                cnt_uest_dict[col] = cnt\n",
    "                max_dict[col] = np.log10(max_uest)\n",
    "                min_dict[col] = np.log10(min_uest)\n",
    "                rel_uest_avg_dict[col] = rel_avg\n",
    "        # fig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(16, 16))\n",
    "        # vals = list(cnt_uest_dict.values())\n",
    "        # ax1.bar(cnt_uest_dict.keys(),vals)\n",
    "        # ax1.set_title('Uest Counts', fontsize=16)\n",
    "        # ax1.set_xlabel('Estimate', fontsize=16)\n",
    "        # ax1.set_ylabel('Counts %', fontsize=16)\n",
    "        # ax1.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        \n",
    "        # max_vals = list(max_dict.values())\n",
    "        # max_vals = [0 if np.isnan(i) else i for i in max_vals]\n",
    "        # # max_vals = np.log10(max_vals)\n",
    "        # min_vals = list(min_dict.values())\n",
    "        # min_vals = [0 if np.isnan(i) else i for i in min_vals]\n",
    "        # # min_vals = np.log10(min_vals)\n",
    "        # bar_width = 0.4\n",
    "        # x = np.arange(len(max_dict.keys()))\n",
    "        # ax2.bar(x - bar_width/2, max_vals, width=bar_width, label='Max Uest')\n",
    "        # ax2.bar(x + bar_width/2, min_vals, width=bar_width, label='Min Uest')\n",
    "        # ax2.set_title(\"Max/Min Uest\", fontsize=16)\n",
    "        # ax2.set_xlabel(\"Estimate\", fontsize=16)\n",
    "        # ax2.set_ylabel(\"log(sec)\", fontsize=16)\n",
    "        # ax2.set_xticks(x)\n",
    "        # ax2.legend()\n",
    "        # ax2.set_xticklabels(max_dict.keys(), rotation=45)\n",
    "        # ax2.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        \n",
    "        # vals = list(rel_uest_avg_dict.values())\n",
    "        # vals = [0 if np.isnan(i) else i for i in vals]\n",
    "        # ax3.bar(rel_uest_avg_dict.keys(),vals)\n",
    "        # ax3.set_title(\"Relative Avg Uest\", fontsize=16)\n",
    "        # ax3.set_ylabel(\"%\", fontsize=16)\n",
    "        # ax3.set_xlabel(\"Estimate\", fontsize=16)\n",
    "        # ax3.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        # plt.tight_layout()\n",
    "        # os.makedirs(f'./plots/errors/risk_aver/uest/', exist_ok=True)\n",
    "        # plt.savefig(f'./plots/errors/risk_aver/uest/{file_name}_err_risk_aver.png', dpi=300, bbox_inches='tight')\n",
    "        # plt.clf()\n",
    "        \n",
    "        # Oest #\n",
    "        max_oest_dict = {}\n",
    "        severe_avg_dict = {}\n",
    "        rel_avg_dict = {}\n",
    "        for col in estimates.columns:\n",
    "            if col!= 'Rate' and col != \"\":  \n",
    "                max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
    "                max_oest_dict[col] = np.log10(max) if max else 0\n",
    "                severe_avg_dict[col] = np.log10(severe) if severe else 0\n",
    "                rel_avg_dict[col] = np.log10(rel) if rel else 0\n",
    "        # fig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(16, 16))\n",
    "        # vals = list(max_oest_dict.values())\n",
    "        # # vals = np.log10(vals)\n",
    "        # vals = [0 if np.isnan(i) else i for i in vals]\n",
    "        # ax1.bar(max_oest_dict.keys(),vals)\n",
    "        # ax1.set_title(\"Max Oest\", fontsize=16)\n",
    "        # ax1.set_ylabel(\"log(sec)\", fontsize=16)\n",
    "        # ax1.set_xlabel(\"Estimate\", fontsize=16)\n",
    "        # ax1.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        \n",
    "        # vals = list(severe_avg_dict.values())\n",
    "        # vals = [0 if np.isnan(i) else i for i in vals]\n",
    "        # # vals = np.log10(vals)\n",
    "        # ax2.bar(severe_avg_dict.keys(),vals)\n",
    "        # ax2.set_title(\"Oest (>1000s) Sum\", fontsize=16)\n",
    "        # ax2.set_ylabel(\"log(sec)\", fontsize=16)\n",
    "        # ax2.set_xlabel(\"Estimate\", fontsize=16)\n",
    "        # ax2.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        \n",
    "        # vals = list(rel_avg_dict.values())\n",
    "        # vals = [0 if np.isnan(i) else i for i in vals]\n",
    "        # # vals = np.log10(vals)\n",
    "        # ax3.bar(rel_avg_dict.keys(),vals)\n",
    "        # ax3.set_title(\"Relative Avg Oest\", fontsize=16)\n",
    "        # ax3.set_ylabel(\"log(%)\", fontsize=16)\n",
    "        # ax3.set_xlabel(\"Estimate\", fontsize=16)\n",
    "        # ax3.tick_params(axis='x', rotation=45,labelsize=16)\n",
    "        # plt.tight_layout()\n",
    "        # os.makedirs(f'./plots/errors/risk_aver/oest/', exist_ok=True)\n",
    "        # plt.savefig(f'./plots/errors/risk_aver/oest/{file_name}_err_risk_aver.png', dpi=300, bbox_inches='tight')\n",
    "        # plt.clf()\n",
    "        \n",
    "        return cnt_uest_dict,max_dict,min_dict,rel_uest_avg_dict,max_oest_dict,severe_avg_dict,rel_avg_dict, smape_dict\n",
    "\n",
    "        ##### Risk netural Errors plots ########\n",
    "        # max_uest_percent_dict = {}\n",
    "        # max_overest_percent_dict = {}\n",
    "        # avg_overest_percent_dict = {}\n",
    "        # for col in estimates.columns:\n",
    "        #     if col==\"Rate\":\n",
    "        #         continue\n",
    "        #     uest_percent,max_overest_percent, avg_overest_percent = get_errors(avg_fork_values,estimates[col])\n",
    "        #     max_uest_percent_dict[col] = uest_percent\n",
    "        #     max_overest_percent_dict[col] = max_overest_percent\n",
    "        #     avg_overest_percent_dict[col] = avg_overest_percent\n",
    "        # fig, (ax1,ax2,ax3) = plt.subplots(3, 1, figsize=(16, 16))\n",
    "        # vals = list(max_uest_percent_dict.values())\n",
    "        # # vals = np.log10(vals)\n",
    "        # ax1.bar(max_uest_percent_dict.keys(),vals)\n",
    "        # ax1.set_title('Avg Underest %', fontsize=10)\n",
    "        # ax1.set_xlabel('Estimate', fontsize=10)\n",
    "        # ax1.set_ylabel('Percent', fontsize=10)\n",
    "        # ax1.tick_params(axis='x', rotation=90)\n",
    "        # vals = list(max_overest_percent_dict.values())\n",
    "        # vals = np.log10(vals)\n",
    "        # ax2.bar(max_overest_percent_dict.keys(),vals)\n",
    "        # ax2.set_title(\"Max Overest %\", fontsize=10)\n",
    "        # ax2.set_ylabel(\"log(Percent)\", fontsize=10)\n",
    "        # ax2.set_xlabel(\"Estimate\", fontsize=10)\n",
    "        # ax2.tick_params(axis='x', rotation=90)\n",
    "        # vals = list(avg_overest_percent_dict.values())\n",
    "        # vals = np.log10(vals)\n",
    "        # ax3.bar(avg_overest_percent_dict.keys(),vals)\n",
    "        # ax3.set_title(\"Avg Overest %\", fontsize=10)\n",
    "        # ax3.set_ylabel(\"log(Percent)\", fontsize=10)\n",
    "        # ax3.set_xlabel(\"Estimate\", fontsize=10)\n",
    "        # ax3.tick_params(axis='x', rotation=90)\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(f'./plots/errors/risk_neut/{file_name}_err_risk_neut.png', dpi=300, bbox_inches='tight')\n",
    "        # plt.clf()\n",
    "\n",
    "    elif plot_type == \"true\":\n",
    "        ### True value plots ###\n",
    "        # x=np.arange(len(orig_values))\n",
    "        # ax1 = plt.gca()\n",
    "        # ax1.set_ylabel(\"log(Trials)\", fontsize=12)\n",
    "        # ax1.scatter(x,np.log10(orig_values), color='black', alpha=0.5,label='Orignal Vals', marker='x')\n",
    "        # ax1.scatter(x,np.log10(avg_fork_values), color='blue', alpha=0.5,label='Avg Fork Vals', marker='x')\n",
    "        # ax1.scatter(x,np.log10(max_fork_values), color='red', alpha=0.5,label='Max Fork Vals', marker='x')\n",
    "        # plt.xlabel(\"Index\", fontsize=12)\n",
    "        # plt.grid(True,linestyle='--',alpha=0.7)\n",
    "        # plt.legend(loc='upper left')\n",
    "        # plt.savefig(f'{file_name}_trials.png', dpi=300, bbox_inches='tight')\n",
    "        # plt.clf()\n",
    "\n",
    "        ### True value Time plots ###\n",
    "        # x=np.arange(len(orig_values))\n",
    "        # ax1 = plt.gca()\n",
    "        # ax1.set_ylabel(\"log(Time)\", fontsize=12)\n",
    "        # time_true_values = np.where(cols_dict['Rate'] != 0, orig_values / cols_dict['Rate'], 0)\n",
    "        # time_max_true_values = np.where(cols_dict['Rate'] != 0, max_fork_values / cols_dict['Rate'], 0)\n",
    "        # time_avg_true_values = np.where(cols_dict['Rate'] != 0, avg_fork_values / cols_dict['Rate'], 0)\n",
    "        # ax1.scatter(x,np.log10(time_true_values), color='black', alpha=0.5,label='Original Vals', marker='x')\n",
    "        # ax1.scatter(x,np.log10(time_avg_true_values), color='blue', alpha=0.5,label='AvgFork Vals', marker='x')\n",
    "        # ax1.scatter(x,np.log10(time_max_true_values), color='red', alpha=0.5,label='MaxFork Vals', marker='x')\n",
    "        # plt.xlabel(\"Index\", fontsize=12)\n",
    "        # plt.grid(True,linestyle='--',alpha=0.7)\n",
    "        # plt.legend(loc='upper left')\n",
    "        # plt.savefig(f'{file_name}_time.png', dpi=300, bbox_inches='tight')\n",
    "        # plt.clf()\n",
    "        pass\n",
    "\n",
    "    elif plot_type == \"ests\":    \n",
    "        #### Estimators ######\n",
    "        for est_type in [\"baseline\",\"novel1\",\"novel2\"]:\n",
    "            hist = \"all\"\n",
    "            rate = np.array(cols_dict['Rate'], dtype=object)\n",
    "            rate = pd.to_numeric(rate, errors='coerce')\n",
    "            rate = np.nan_to_num(rate, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "\n",
    "            if est_type == \"baseline\":\n",
    "                time_AvSeed = np.where(rate != 0, get_col('AvPath',hist,estimates) / rate, 0)\n",
    "                time_AvFeat = np.where(rate != 0, get_col('AvFeat',hist,estimates) / rate, 0)\n",
    "                time_Markov = np.where(rate != 0, get_col('Markov',hist,estimates) / rate, 0)\n",
    "            elif est_type == \"novel1\":\n",
    "                time_max = np.where(rate != 0, get_col('MaxTrials',hist,estimates) / rate, 0)\n",
    "            elif est_type == \"novel2\":\n",
    "                time_atl = np.where(rate != 0, get_col('ATL',hist,estimates) / rate, 0)\n",
    "                time_geom_nonident = np.where(rate != 0, get_col('Extr',hist,estimates) / rate, 0)\n",
    "            time_LLaplace = np.where(rate != 0, cols_dict['LLaplace'] / rate, 0)\n",
    "            time_LGT = np.where(rate != 0, cols_dict['LGT'] / rate, 0)\n",
    "            time_max_true_values = np.where(rate != 0, max_fork_values / rate, 0)\n",
    "            # time_avg_true_values = np.where(rate != 0, avg_fork_values / rate, 0)\n",
    "            # time_orig_values = np.where(rate != 0, orig_values / rate, 0)\n",
    "            \n",
    "            ## Risk averse Estimators Time plots ###\n",
    "            x=np.arange(len(orig_values))\n",
    "            ax1 = plt.gca()\n",
    "            if est_type == \"novel1\":\n",
    "                ax1.scatter(x,np.log10(time_max),color='green',alpha=0.2,label=f'Max Trials {hist}')\n",
    "                ax1.scatter(x,np.log10(time_Markov),color='red',alpha=0.2,label=f'Markov 95% {hist}')\n",
    "            if est_type == \"novel2\":\n",
    "                ax1.scatter(x,np.log10(time_geom_nonident),color='deeppink',alpha=0.2,label=f'Extr. Val Set of Seeds {hist}')\n",
    "                ax1.scatter(x,np.log10(time_atl),color='blue',alpha=0.2,label=f'ATL {hist}')\n",
    "            if est_type == \"baseline\":                 \n",
    "                ax1.scatter(x,np.log10(time_AvSeed),color='lightblue',alpha=0.2,label=f'AvSeed {hist}')\n",
    "                ax1.scatter(x,np.log10(time_AvFeat),color='lightgreen',alpha=0.2,label=f'AvFeat {hist}')\n",
    "            ax1.scatter(x,np.log10(time_LLaplace),color='yellow',alpha=0.2,label='LLaplace')\n",
    "            ax1.scatter(x,np.log10(time_LGT),color='cyan',alpha=0.2,label='LGT')\n",
    "            ax1.scatter(x,np.log10(time_max_true_values), color='black', alpha=0.2,label='MaxFork Vals', marker='x')\n",
    "            ax1.legend(loc='upper left',fontsize=5)\n",
    "            ax1.set_ylabel(\"log(sec)\", fontsize=10)\n",
    "            plt.xlabel(\"Discoveries\", fontsize=10)\n",
    "            plt.grid(True,linestyle='--',alpha=0.7)\n",
    "            os.makedirs(f'./plots/est_risk_aver/{est_type}/{hist}', exist_ok=True)\n",
    "            plt.savefig(f'./plots/est_risk_aver/{est_type}/{hist}/{file_name}_est_risk_aver.png', dpi=300, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "\n",
    "            ### Risk neutral Estimators Time plots ###\n",
    "            # x=np.arange(len(orig_values))\n",
    "            # ax1 = plt.gca()\n",
    "            # if est_type == \"novel1\":\n",
    "            #     ax1.scatter(x,np.log10(time_max),color='green',alpha=0.2,label=f'Max {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_atl),color='blue',alpha=0.2,label=f'ATL {hist}')\n",
    "            # if est_type == \"novel2\":\n",
    "            #     ax1.scatter(x,np.log10(time_geom_nonident),color='deeppink',alpha=0.2,label=f'Geom Non-Ident {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_geom_ident),color='coral',alpha=0.2,label=f'Geom Ident {hist}')\n",
    "            # if est_type == \"baseline\":                 \n",
    "            #     ax1.scatter(x,np.log10(time_AvSeed),color='lightblue',alpha=0.2,label=f'AvSeed {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_AvFeat),color='lightgreen',alpha=0.2,label=f'AvFeat {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_Markov),color='red',alpha=0.2,label=f'Markov 95% {hist}')\n",
    "            # ax1.scatter(x,np.log10(time_LLaplace),color='yellow',alpha=0.2,label='LLaplace')\n",
    "            # ax1.scatter(x,np.log10(time_LGT),color='cyan',alpha=0.2,label='LGT')\n",
    "            # ax1.scatter(x,np.log10(time_avg_true_values), color='black', alpha=0.2,label='AvgFork Vals', marker='x')\n",
    "            # ax1.legend(loc='upper left',fontsize=5)\n",
    "            # ax1.set_ylabel(\"log(sec)\", fontsize=10)\n",
    "            # plt.xlabel(\"Discoveries\", fontsize=10)\n",
    "            # plt.grid(True,linestyle='--',alpha=0.7)\n",
    "            # os.makedirs(f'./plots/est_risk_neut/{est_type}/{hist}', exist_ok=True)\n",
    "            # plt.savefig(f'./plots/est_risk_neut/{est_type}/{hist}/{file_name}_est_risk_neut.png', dpi=300, bbox_inches='tight')\n",
    "            # plt.clf()\n",
    "\n",
    "            ### Original Estimators Time plots ###\n",
    "            # x=np.arange(len(orig_values))\n",
    "            # ax1 = plt.gca()\n",
    "            # if est_type == \"novel1\":\n",
    "            #     ax1.scatter(x,np.log10(time_max),color='green',alpha=0.2,label=f'Max {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_atl),color='blue',alpha=0.2,label=f'ATL {hist}')\n",
    "            # if est_type == \"novel2\":\n",
    "            #     ax1.scatter(x,np.log10(time_geom_nonident),color='deeppink',alpha=0.2,label=f'Geom Non-Ident {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_geom_ident),color='coral',alpha=0.2,label=f'Geom Ident {hist}')\n",
    "            # if est_type == \"baseline\":                 \n",
    "            #     ax1.scatter(x,np.log10(time_AvSeed),color='lightblue',alpha=0.2,label=f'AvSeed {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_AvFeat),color='lightgreen',alpha=0.2,label=f'AvFeat {hist}')\n",
    "            #     ax1.scatter(x,np.log10(time_Markov),color='red',alpha=0.2,label=f'Markov 95% {hist}')\n",
    "            # ax1.scatter(x,np.log10(time_LLaplace),color='yellow',alpha=0.2,label='LLaplace')\n",
    "            # ax1.scatter(x,np.log10(time_LGT),color='cyan',alpha=0.2,label='LGT')\n",
    "            # ax1.scatter(x,np.log10(time_orig_values), color='black', alpha=0.2,label='Orig Vals', marker='x')\n",
    "            # ax1.legend(loc='upper left',fontsize=5)\n",
    "            # ax1.set_ylabel(\"log(sec)\", fontsize=10)\n",
    "            # plt.xlabel(\"Discoveries\", fontsize=10)\n",
    "            # plt.grid(True,linestyle='--',alpha=0.7)\n",
    "            # os.makedirs(f'./plots/est_orig/{est_type}/{hist}', exist_ok=True)\n",
    "            # plt.savefig(f'./plots/est_orig/{est_type}/{hist}/{file_name}_est_orig.png', dpi=300, bbox_inches='tight')\n",
    "            # plt.clf()\n",
    "\n",
    "    #     ### Succ Val Freqs ###\n",
    "    # ax1 = plt.gca()\n",
    "    # ax1.hist(succ_values,bins=50,label=f'Succ Trials')\n",
    "    # ax1.legend(loc='upper left',fontsize=5)\n",
    "    # ax1.set_ylabel(\"Frequency\", fontsize=10)\n",
    "    # plt.xlabel(\"Succ Trials\", fontsize=10)\n",
    "    # plt.grid(True,linestyle='--',alpha=0.7)\n",
    "    # plt.savefig(f'{file_name}_succ_freq.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.clf()\n",
    "\n",
    "def combine_errors(aggregated_errors):\n",
    "    # pattern = re.compile(r'AvPath')\n",
    "    for error in aggregated_errors.items():\n",
    "        # filtered_keys = [key for key in error[1].keys() if re.search(pattern, key)]\n",
    "        # if filtered_keys:\n",
    "        if True:\n",
    "            fig,ax = plt.subplots(1,1,figsize=(12, 6))\n",
    "            ax.set_ylabel(error[0],fontsize=14)\n",
    "            ax.set_xlabel(\"Estimator\",fontsize=14)\n",
    "            ax.tick_params(axis='x', rotation=90,labelsize=14)\n",
    "            ax.tick_params(axis='y', labelsize=14)\n",
    "            ax.set_title(error[0], fontsize=14)\n",
    "            bars = ax.bar(error[1].keys(), error[1].values())\n",
    "            # bars =ax.bar(filtered_keys, [error[1][key] for key in filtered_keys])\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.2f}\", ha='center', va='bottom')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'./plots/errors/risk_aver/{error[0]}.jpg', dpi=300, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "\n",
    "def combine_ests(file_names):\n",
    "    n_files = len(file_names)\n",
    "    n_cols = 3  \n",
    "    n_rows = (n_files + n_cols - 1) // n_cols \n",
    "\n",
    "    for est_type in [\"baseline\",\"novel1\",\"novel2\"]:\n",
    "        fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.3, n_rows*3.5))\n",
    "        for i, file_name in enumerate(file_names):\n",
    "            df = pd.read_csv(f'./data/csv/{file_name}.csv') # cache this\n",
    "            columns = df.columns.tolist()\n",
    "            max_fork_values = list(df['MaxFork'])\n",
    "            estimates = df[columns[8:]] ## dont hardcode\n",
    "            cols_dict = {\n",
    "                'LLaplace': get_col('LLaplace', 0,estimates),\n",
    "                'LGT': get_col('LGT', 0,estimates),\n",
    "                'Rate': get_col('Rate',0,estimates),\n",
    "            }\n",
    "            hist = \"all\"\n",
    "            rate = np.array(cols_dict['Rate'], dtype=object)\n",
    "            rate = pd.to_numeric(rate, errors='coerce')\n",
    "            rate = np.nan_to_num(rate, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "\n",
    "            if est_type == \"baseline\":\n",
    "                time_AvSeed = np.where(rate != 0, get_col('AvPath',hist,estimates) / rate, 0)\n",
    "                time_AvFeat = np.where(rate != 0, get_col('AvFeat',hist,estimates) / rate, 0)\n",
    "            elif est_type == \"novel1\":\n",
    "                time_Markov = np.where(rate != 0, get_col('Markov',hist,estimates) / rate, 0)\n",
    "                time_max = np.where(rate != 0, get_col('MaxTrials',hist,estimates) / rate, 0)\n",
    "            elif est_type == \"novel2\":\n",
    "                time_atl = np.where(rate != 0, get_col('ATL',hist,estimates) / rate, 0)\n",
    "                time_geom_nonident = np.where(rate != 0, get_col('Extr',hist,estimates) / rate, 0)\n",
    "                # geomexp = np.array(get_col('GeomIdent', hist,estimates), dtype=object)\n",
    "                # geomexp = pd.to_numeric(geomexp, errors='coerce')\n",
    "                # geomexp = np.nan_to_num(geomexp, nan=0.0)\n",
    "                # time_geom_ident = np.divide(geomexp, rate, where=rate != 0, out=np.zeros_like(rate, dtype=float))\n",
    "            time_LLaplace = np.where(rate != 0, cols_dict['LLaplace'] / rate, 0)\n",
    "            time_LGT = np.where(rate != 0, cols_dict['LGT'] / rate, 0)\n",
    "            time_max_true_values = np.where(rate != 0, max_fork_values / rate, 0)\n",
    "            row = i // n_cols\n",
    "            col = i % n_cols\n",
    "            ax = axs[row, col]\n",
    "            \n",
    "            x = np.arange(len(max_fork_values))  \n",
    "            if est_type == \"novel1\":\n",
    "                l1 = ax.scatter(x, np.log10(time_max), color='green', alpha=0.5, label=f'Max Trial')\n",
    "                l2 = ax.scatter(x, np.log10(time_Markov), color='red', alpha=0.5, label=f'Markov 95%')\n",
    "            if est_type == \"novel2\":\n",
    "                l1 = ax.scatter(x, np.log10(time_geom_nonident), color='deeppink', alpha=0.5, label=f'Extr. Val Set of Seeds')\n",
    "                # l2 = ax.scatter(x, np.log10(time_geom_ident), color='coral', alpha=0.5, label=f'Extr. Val Single Seed')\n",
    "                l2 = ax.scatter(x, np.log10(time_atl), color='blue', alpha=0.5, label=f'At Least One Succ')\n",
    "            if est_type == \"baseline\":                 \n",
    "                l1 = ax.scatter(x, np.log10(time_AvSeed), color='lightblue', alpha=0.5, label=f'Avg Path Disc')\n",
    "                l2 = ax.scatter(x, np.log10(time_AvFeat), color='lightgreen', alpha=0.5, label=f'Avg Feat Disc')\n",
    "            l3 = ax.scatter(x, np.log10(time_LLaplace), color='yellow', alpha=0.5, label='LLaplace')\n",
    "            l4 = ax.scatter(x, np.log10(time_LGT), color='cyan', alpha=0.5, label='LGT')\n",
    "            l5 = ax.scatter(x, np.log10(time_max_true_values), color='black', alpha=0.2, label='Max Fork Vals', marker='x')\n",
    "            if i == 0:  # Only add once\n",
    "                handles = [l1, l2, l3 , l4, l5]\n",
    "                labels = [l.get_label() for l in handles if l is not None]\n",
    "            ax.grid(True, linestyle='--', alpha=0.7)\n",
    "            ax.set_title(file_name)\n",
    "\n",
    "        if n_files < n_rows * n_cols:\n",
    "            for i in range(n_files, n_rows * n_cols):\n",
    "                row = i // n_cols\n",
    "                col = i % n_cols\n",
    "                axs[row, col].axis('off')\n",
    "        fig.supxlabel('Discoveries', fontsize=14)\n",
    "        fig.supylabel('log(sec)', fontsize=14)\n",
    "        fig.legend(handles=[h for h in handles if h is not None], \n",
    "           labels=[l for l in labels if l], \n",
    "           loc='lower center', \n",
    "           bbox_to_anchor=(0.5, -0.07), \n",
    "           ncol=len(labels))\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        os.makedirs(f'./plots/est_risk_aver/grid/', exist_ok=True)\n",
    "        plt.savefig(f'./plots/est_risk_aver/grid/{est_type}.jpg', dpi=300, bbox_inches='tight')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: divide by zero encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: divide by zero encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: divide by zero encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: divide by zero encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: divide by zero encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  smape = get_smape(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: divide by zero encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  cnt,max_uest,min_uest,rel_avg = get_uests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: divide by zero encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_17924\\1720083501.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  max, severe,rel = get_oests(max_fork_values/rate,estimates[col]/rate)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# file_names = ['json','zlib','curl','libxml','openh','freetype2']\n",
    "file_names = ['json.1','zlib.1','libpcap.1','libxml.1','libpng.1','freetype2.1']\n",
    "# file_names = ['libpcap.1']\n",
    "aggregated_errors  = {}\n",
    "for file_name in file_names:\n",
    "    # generate_csv(file_name)\n",
    "    # plot_stats(file_name,\"ests\")\n",
    "    cnt_uest_dict,max_dict,min_dict,rel_uest_avg_dict,max_oest_dict,severe_avg_dict,rel_avg_dict,smape_dict = plot_stats(file_name,\"errors\")\n",
    "    dicts_to_aggregate = {\n",
    "    'Count Uest': ('Uest Count %', cnt_uest_dict),\n",
    "    'Max Uest': ('Max Uest log(s)', max_dict),\n",
    "    'Min Uest': ('Min Uest log(s)', min_dict),\n",
    "    'Relative Uest': ('Relative Uest %', rel_uest_avg_dict),\n",
    "    'Max Oest': ('Max Oest log(s)', max_oest_dict),\n",
    "    'Severe Oest': ('Severe Oest Sum log(s)', severe_avg_dict),\n",
    "    'Relative Oest': ('Relative Oest log(%)', rel_avg_dict),\n",
    "    'SMAPE': ('SMAPE',smape_dict)\n",
    "    }\n",
    "\n",
    "    for aggregate_key, dict_to_process in dicts_to_aggregate.values():\n",
    "        for estimator, value in dict_to_process.items():\n",
    "            aggregated_errors.setdefault(aggregate_key, {}).setdefault(estimator, 0)\n",
    "            aggregated_errors[aggregate_key][estimator] += (value)/len(file_names)\n",
    "# combine_ests(file_names)\n",
    "combine_errors(aggregated_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
